{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idris Nemsia\n",
    "In this file, we train and save the SNN on 80000 pairs of images from the Olivetti faces dataset. Code sections include data loading and organizing, steps to building the model, and then training it.\n",
    "\n",
    "The model structure requires us to build the snn in two parts: \n",
    "- Build the feature extraction layers (here referred to as cnn_part)\n",
    "- Build the entire snn structure to start training \n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Data manipulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Model training \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Lambda, BatchNormalization, ReLU, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features): (400, 64, 64, 1)\n",
      "Shape of y (labels): (400,)\n",
      "IMG_SHAPE =  (64, 64, 1)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "# Load the Olivetti faces dataset\n",
    "faces = fetch_olivetti_faces()\n",
    "# Extract the images and expand their dimensions to include a channel dimension\n",
    "X = faces.images\n",
    "X = np.expand_dims(X, axis=-1) \n",
    "\n",
    "# Extract the labels\n",
    "y = faces.target\n",
    "# Print the shape of the data\n",
    "print(f'Shape of X (features): {X.shape}')  \n",
    "print(f'Shape of y (labels): {y.shape}')    \n",
    "\n",
    "# Get the of occurances of each label \n",
    "unique_labels, _ = np.unique(y, return_counts=True)\n",
    "\n",
    "# Get image shape\n",
    "IMG_SHAPE = X[0].shape\n",
    "print(f\"IMG_SHAPE = \", IMG_SHAPE)\n",
    "\n",
    "# Print the labels of the individuals\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates an equal amount of randomly selected positive and negative pairs\n",
    "# Given the images, their labels, the list of unique labels, and the number of pairs to create,\n",
    "# it returns two numpy arrays containing pairs of images and their labels (1 for similar, 0 for different) \n",
    "def create_balanced_pairs(X, y, unique_labels, num_pairs=1000):\n",
    "    # Initialize arrays\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    half_pairs = num_pairs // 2  \n",
    "    \n",
    "    # Step 1: Create positive pairs\n",
    "    for _ in range(half_pairs):\n",
    "        # Randomly select a class\n",
    "        digit_class = np.random.choice(unique_labels)\n",
    "        \n",
    "        # Get indices for this class\n",
    "        indices = np.where(y == digit_class)[0]\n",
    "        \n",
    "        # Select 2 random indices from the same class\n",
    "        if len(indices) >= 2:\n",
    "            idx1, idx2 = np.random.choice(indices, size=2, replace=False)\n",
    "            image1 = X[idx1]\n",
    "            image2 = X[idx2]\n",
    "            \n",
    "            # Add the pair and label it as 1 (positive pair)\n",
    "            pairs.append([image1, image2])\n",
    "\n",
    "            #Add a positive label\n",
    "            labels.append(1.)\n",
    "    \n",
    "    # Step 2: Create negative pairs\n",
    "    for _ in range(half_pairs):\n",
    "        # Randomly select two different classes\n",
    "        class1, class2 = np.random.choice(unique_labels, size=2, replace=False)\n",
    "        \n",
    "        # Get indices for each class\n",
    "        indices1 = np.where(y == class1)[0]\n",
    "        indices2 = np.where(y == class2)[0]\n",
    "        \n",
    "        # Select one image from each class\n",
    "        idx1 = np.random.choice(indices1)\n",
    "        idx2 = np.random.choice(indices2)\n",
    "        \n",
    "        image1 = X[idx1]\n",
    "        image2 = X[idx2]\n",
    "        \n",
    "        # Add the pair \n",
    "        pairs.append([image1, image2])\n",
    "        \n",
    "        # Add a negative label\n",
    "        labels.append(0.)\n",
    "    \n",
    "    # Convert pairs and labels to numpy arrays\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits an array into training and testing subarrays based on a training size percentage. \n",
    "# It is used later to split the data based on the unique labels present, so that 30 people's images\n",
    "# are used for training, and 10 people's images are used for one-shot trials.\n",
    "def split_array(array, percentage):\n",
    "    # Ensure the percentage is valid\n",
    "    if not 0 <= percentage <= 1:\n",
    "        raise ValueError(\"Percentage must be between 0 and 1.\")\n",
    "    \n",
    "    # Calculate the number of elements for the split\n",
    "    split_size = int(len(array) * percentage)\n",
    "    \n",
    "    # Split the array in order without shuffling\n",
    "    train_part = array[:split_size]\n",
    "    test_part = array[split_size:]\n",
    "    \n",
    "    return train_part, test_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_labels_train = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29] \n",
      "unique_labels_test = [30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "# Set the number of pairs used during training\n",
    "NUM_PAIRS = 80000\n",
    "\n",
    "# Split the identities of the individuals for training and testing\n",
    "unique_labels_train, unique_labels_test = split_array(unique_labels, 0.75)\n",
    "\n",
    "# Get the training data and the labels\n",
    "pairs_train, labels_train = create_balanced_pairs(X, y, unique_labels_train, NUM_PAIRS)\n",
    "\n",
    "# Print the identities used for training and testing\n",
    "print(f'unique_labels_train = {unique_labels_train} \\nunique_labels_test = {unique_labels_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First image in each pair\n",
    "X1_train = np.array([pair[0] for pair in pairs_train])  \n",
    "# Second image in each pair\n",
    "X2_train = np.array([pair[1] for pair in pairs_train])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function visualizes a subset of the pairs used in the data\n",
    "def visualize_pairs(X1,X2,y,num_pairs,pairs_per_row, title=\"Pair samples from Training Data\",labels_title=\"True label\",padding=10):\n",
    "    if pairs_per_row == 0:\n",
    "        return \n",
    "    rows = num_pairs // pairs_per_row\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(rows, pairs_per_row * 2, figsize=(12, 3 * rows))\n",
    "    fig.subplots_adjust(wspace=0.01, hspace=0.8)  # Minimal space between images in a pair; more between rows\n",
    "\n",
    "    # Plot each pair with its label\n",
    "    for i in range(num_pairs):\n",
    "        row = i // pairs_per_row\n",
    "        col = (i % pairs_per_row) * 2  # Each pair occupies two columns\n",
    "\n",
    "        # Display the first image of the pair (X1_train[i])\n",
    "        axes[row, col].imshow(X1[i], cmap='gray')  # Adjust cmap as needed\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "        # Display the second image of the pair (X2_train[i])\n",
    "        axes[row, col + 1].imshow(X2[i], cmap='gray')  # Adjust cmap as needed\n",
    "        axes[row, col + 1].axis('off')\n",
    "\n",
    "        # Add the label above the pair, centered\n",
    "        label = f\"{labels_title}: {y[i]}\"\n",
    "        axes[row, col].set_title(label, fontsize=10, color=\"blue\", pad=padding, loc='center', x=1.05)\n",
    "        axes[row, col + 1].set_title(\"\")  # Empty title for the second image in each pair\n",
    "\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "#visualize_pairs(X1_train, X2_train, labels_train,32,8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "# This function was created to experiment with different parameters and structures for the feature extraction\n",
    "# layers, which I refer to here as cnn_part. This allowed me to find the most optimal complexity of the feature\n",
    "# extraction layers for my task, and facilitated keeping track of experiments. At the end, architecture C\n",
    "# provided the best results, so I ended up saving that as the structure of my model, and the reported \n",
    "# results follow that structure.\n",
    "def create_model(architecture, IMG_SHAPE):\n",
    "    cnn_part = Sequential()\n",
    "\n",
    "    if architecture == 'A':\n",
    "        # Architecture A\n",
    "        cnn_part.add(Conv2D(filters=64, kernel_size=(10, 10), input_shape=IMG_SHAPE, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Conv2D(128, (7, 7), strides=1, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Conv2D(256, (4, 4), strides=1, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Flatten())\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(Dense(128, activation=\"sigmoid\"))\n",
    "\n",
    "    elif architecture == 'B':\n",
    "        # Architecture B: Similar but with different kernel sizes and more layers\n",
    "        cnn_part.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=IMG_SHAPE, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Conv2D(64, (5, 5), strides=1, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Flatten())\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(Dense(128, activation=\"sigmoid\"))\n",
    "\n",
    "    elif architecture == 'C':\n",
    "        # Architecture C: Adding more depth\n",
    "        cnn_part.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=IMG_SHAPE, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Conv2D(256, (3, 3), strides=1, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Flatten())\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(Dense(128, activation=\"sigmoid\"))\n",
    "\n",
    "    elif architecture == 'D':\n",
    "        # Architecture D: Global Average Pooling instead of Flatten\n",
    "        cnn_part.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=IMG_SHAPE, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Conv2D(128, (3, 3), strides=1, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        cnn_part.add(Conv2D(256, (3, 3), strides=1, kernel_regularizer=l2(2e-4)))\n",
    "        cnn_part.add(BatchNormalization())\n",
    "        cnn_part.add(ReLU())\n",
    "        cnn_part.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        cnn_part.add(Dropout(0.3))\n",
    "\n",
    "        # Add Global Average Pooling instead of Flatten\n",
    "        cnn_part.add(GlobalAveragePooling2D())\n",
    "\n",
    "        cnn_part.add(BatchNormalization())  \n",
    "        cnn_part.add(Dense(128, activation=\"sigmoid\"))\n",
    "\n",
    "    return cnn_part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set parameters\n",
    "IMG_SHAPE = (64, 64, 1)  # Input shape for images\n",
    "# Final chosen architecture\n",
    "architecture = 'C'  \n",
    "# Batch size\n",
    "batch_sizes = [32]  # Batch sizes to test\n",
    "epochs = 25  # Number of epochs to train\n",
    "\n",
    "folder_path = f\"trained_model\"\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the architecture C with batch size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/25\n",
      "\u001b[1m  50/2500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29:27\u001b[0m 722ms/step - loss: 0.6068"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Train the model on the training pairs\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43msnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Define the filename and save the trained model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/snn_final.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary modules for optimizer and early stopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Print information about the current training configuration\n",
    "print(f\"Training the architecture {architecture} with batch size {32}\")\n",
    "\n",
    "# Create the CNN subnetwork for the Siamese model using architecture \"C\"\n",
    "cnn_part = create_model(architecture, IMG_SHAPE)\n",
    "        \n",
    "# Define two input layers for the pair of input images\n",
    "input1, input2 = Input(shape=IMG_SHAPE, name=\"Image1\"), Input(shape=IMG_SHAPE, name=\"Image2\")\n",
    "\n",
    "# Pass both inputs through the shared CNN model to get their embeddings\n",
    "embedding1, embedding2 = cnn_part(input1), cnn_part(input2)\n",
    "        \n",
    "# Calculate the absolute difference between the two embeddings\n",
    "distance = Lambda(lambda tensors: abs(tensors[0] - tensors[1]))([embedding1, embedding2])\n",
    "\n",
    "# Pass the distance through a Dense layer with sigmoid activation to get similarity score\n",
    "final_output = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "# Create the full Siamese model\n",
    "snn = Model(inputs=[input1, input2], outputs=final_output)\n",
    "        \n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "snn.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=None)\n",
    "\n",
    "# Define early stopping to halt training when validation performance stops improving\n",
    "es = EarlyStopping(patience=3)\n",
    "\n",
    "# Train the model on the training pairs\n",
    "snn.fit(x=[X1_train, X2_train], \n",
    "        y=labels_train, \n",
    "        batch_size=32, \n",
    "        epochs=epochs,\n",
    "        callbacks=[es],\n",
    "        shuffle=True)\n",
    "\n",
    "# Define the filename and save the trained model\n",
    "model_filename = f\"{folder_path}/snn_final.h5\"\n",
    "snn.save(model_filename)\n",
    "\n",
    "# confirm that the model was saved\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
